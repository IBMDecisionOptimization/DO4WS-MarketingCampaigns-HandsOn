{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying a Decision Optimization model with Watson Machine Learning\n",
    "\n",
    "This notebook shows you how to deploy a Decision Optimization model, create and monitor jobs, and get solutions using the Watson Machine Learning Python Client.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Install the Watson Machine Learning client API](#setup)\n",
    "2. [Create a client instance](#create)\n",
    "3. [Prepare your model archive](#prepare)\n",
    "4. [Upload your model on Watson Machine Learning](#upload)\n",
    "5. [Create a deployment](#deploy)\n",
    "6. [Create and monitor a job with inline data for your deployed model](#job)\n",
    "7. [Display the solution](#display)\n",
    "8. [Solve another problem using the same deployment](#problem)\n",
    "9. [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "### Set up the Watson Machine Learning client\n",
    "\n",
    "Before you use the sample code in this notebook, you need to:\n",
    "\n",
    "- create a <a href=\"https://cloud.ibm.com/catalog/services/machine-learning\" target=\"_blank\" rel=\"noopener noreferrer\">Watson Machine Learning (WML) Service</a> instance. A free plan is offered and information about how to create the instance can be found at <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-setup.html\" target=\"_blank\" rel=\"noopener noreferrer\"> https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/wml-setup.html.</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and then import the Watson Machine Learning client library. This notebook uses the preview Python client based on v4 of Watson Machine Learning APIs. \n",
    "\n",
    "**Important** Do not load both Python client libraries into a notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling watson-machine-learning-client-1.0.371:\n",
      "  Successfully uninstalled watson-machine-learning-client-1.0.371\n"
     ]
    }
   ],
   "source": [
    "# Uninstall the Watson Machine Learning client Python client based on v3 APIs\n",
    "\n",
    "!pip uninstall watson-machine-learning-client -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting watson-machine-learning-client-V4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/2b/a6be1a2b36138835a66b007f128ffa1ab52398178c4b564534fdc1d30743/watson_machine_learning_client_V4-1.0.34-py3-none-any.whl (974kB)\n",
      "\u001b[K     |████████████████████████████████| 983kB 312kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (2.4.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (4.31.1)\n",
      "Requirement already satisfied: tabulate in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (0.8.2)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (1.24.1)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (2.21.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (2019.6.16)\n",
      "Requirement already satisfied: lomond in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (0.3.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (0.24.1)\n",
      "Requirement already satisfied: ibm-cos-sdk-core==2.*,>=2.0.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-cos-sdk->watson-machine-learning-client-V4) (2.4.3)\n",
      "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.*,>=2.0.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-cos-sdk->watson-machine-learning-client-V4) (2.4.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->watson-machine-learning-client-V4) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->watson-machine-learning-client-V4) (3.0.4)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lomond->watson-machine-learning-client-V4) (1.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas->watson-machine-learning-client-V4) (2.7.5)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas->watson-machine-learning-client-V4) (2018.9)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas->watson-machine-learning-client-V4) (1.15.4)\n",
      "Requirement already satisfied: docutils>=0.10 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client-V4) (0.14)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client-V4) (0.9.3)\n",
      "Installing collected packages: watson-machine-learning-client-V4\n",
      "Successfully installed watson-machine-learning-client-V4-1.0.34\n"
     ]
    }
   ],
   "source": [
    "# Install the WML client API\n",
    "\n",
    "!pip install watson-machine-learning-client-V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='create'></a>\n",
    "### Create a client instance\n",
    "\n",
    "Use your Watson Machine Learning credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a client using credentials\n",
    "wml_credentials = {\n",
    "  \"apikey\": \"dGuBkKsOIA90OIHL_j3IxRkkTUerJJXEeRu5m5r2yhNO\",\n",
    "  \"iam_apikey_description\": \"Auto generated apikey during resource-key operation for Instance - crn:v1:bluemix:public:pm-20:eu-de:a/05b089c618b6d54d15a9116170521ef8:9fe12ac2-0282-4468-8466-30ec9b4b14dd::\",\n",
    "  \"iam_apikey_name\": \"auto-generated-apikey-59eb1604-0716-4382-b06c-7c0ac31ec13d\",\n",
    "  \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Writer\",\n",
    "  \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::a/05b089c618b6d54d15a9116170521ef8::serviceid:ServiceId-d9b8ba66-b3a2-46b8-b334-1bebb3055d95\",\n",
    "  \"instance_id\": \"9fe12ac2-0282-4468-8466-30ec9b4b14dd\",\n",
    "  \"password\": \"3260c811-0cdb-4604-b1bb-8378c4daaf52\",\n",
    "  \"url\": \"https://eu-de.ml.cloud.ibm.com\",\n",
    "  \"username\": \"59eb1604-0716-4382-b06c-7c0ac31ec13d\"\n",
    "}\n",
    "\n",
    "client = WatsonMachineLearningAPIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.34'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prepare'></a>\n",
    "### Prepare your model archive\n",
    "\n",
    "Put the model.py file in a subdirectory and create a tar.gz file. The model consists of two parts:\n",
    "* some functions to create an `inputs` dictionary from files and create files from an `outputs` dictionary,\n",
    "* the real optimization model which uses the inputs and outputs dictionaries.\n",
    "\n",
    "Use the `write_file` command to write these models to a `main.py` file. \n",
    "\n",
    "Use the `tar` command to create a tar archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%mkdir model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model/main.py\n",
    "\n",
    "from docplex.util.environment import get_environment\n",
    "from os.path import splitext\n",
    "import pandas\n",
    "from six import iteritems\n",
    "\n",
    "def get_all_inputs():\n",
    "    '''Utility method to read a list of files and return a tuple with all\n",
    "    read data frames.\n",
    "    Returns:\n",
    "        a map { datasetname: data frame }\n",
    "    '''\n",
    "    result = {}\n",
    "    env = get_environment()\n",
    "    for iname in [f for f in os.listdir('.') if splitext(f)[1] == '.csv']:\n",
    "        with env.get_input_stream(iname) as in_stream:\n",
    "            df = pandas.read_csv(in_stream)\n",
    "            datasetname, _ = splitext(iname)\n",
    "            result[datasetname] = df\n",
    "    return result\n",
    "\n",
    "def write_all_outputs(outputs):\n",
    "    '''Write all dataframes in ``outputs`` as .csv.\n",
    "\n",
    "    Args:\n",
    "        outputs: The map of outputs 'outputname' -> 'output df'\n",
    "    '''\n",
    "    for (name, df) in iteritems(outputs):\n",
    "        csv_file = '%s.csv' % name\n",
    "        print(csv_file)\n",
    "        with get_environment().get_output_stream(csv_file) as fp:\n",
    "            if sys.version_info[0] < 3:\n",
    "                fp.write(df.to_csv(index=False, encoding='utf8'))\n",
    "            else:\n",
    "                fp.write(df.to_csv(index=False).encode(encoding='utf8'))\n",
    "    if len(outputs) == 0:\n",
    "        print(\"Warning: no outputs written\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to model/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a model/main.py\n",
    "\n",
    "# Load CVS files into inputs dictionnary\n",
    "inputs = get_all_inputs()\n",
    "\n",
    "#dd-markdown ### Extract data from inputs dictionnary\n",
    "#dd-markdown In DO for DSX the data is passed as a dictionnary indexed by table names\n",
    "#dd-cell\n",
    "import os, pandas as pd\n",
    "\n",
    "df_campaign = inputs['campaign']\n",
    "campaigns = df_campaign['id'].values\n",
    "df_campaign.set_index('id', inplace=True)\n",
    "\n",
    "df_customer = inputs['customer'] \n",
    "customers = df_customer['id'].values\n",
    "df_customer.set_index('id', inplace=True)\n",
    "\n",
    "df_candidate = inputs['candidate']\n",
    "df_candidate.set_index([\"Customer\",\"Campaign\"], inplace = True)\n",
    "\n",
    "df_candidate.head()\n",
    "#dd-markdown ### Import DO package and create a new model\n",
    "#dd-cell\n",
    "from docplex.mp.model import Model\n",
    "mdl = Model(\"MarketingSmall\")\n",
    "#dd-markdown ### Create decision variables\n",
    "#dd-markdown We will have one \"selection\" binary decision variable for each pair of cusomer and campaign  \n",
    "#dd-cell\n",
    "selected = mdl.binary_var_matrix(keys1=customers, keys2=campaigns, name=\"selected\")\n",
    "df_selected = pd.DataFrame({'selected': selected})\n",
    "df_selected.index.names=['customer', 'campaign']\n",
    "#dd-markdown ### Create and add objective\n",
    "#dd-markdown The objective is to maximize expected revenue\n",
    "#dd-cell\n",
    "expected_revenue = mdl.sum( selected[customer,campaign] * df_candidate['expected value'][customer,campaign] for customer in customers for campaign in campaigns) \n",
    "mdl.add_kpi(expected_revenue, \"Expected revenue\");\n",
    "mdl.maximize(expected_revenue);\n",
    "#dd-markdown ### Create and add constraints\n",
    "#dd-markdown * For each campaign the number of selected customers is lower than \"max customers\"\n",
    "#dd-cell\n",
    "for campaign in campaigns:\n",
    "    mdl.add_constraint( mdl.sum( selected[customer,campaign] for customer in customers) <= df_campaign['max customers'][campaign])\n",
    "#dd-markdown * For each customer, there is at most one selected campaign\n",
    "#dd-cell\n",
    "for customer in customers:\n",
    "    mdl.add_constraint( mdl.sum( selected[customer,campaign] for campaign in campaigns) <= 1)\n",
    "#dd-cell\n",
    "mdl.print_information()\n",
    "#dd-markdown ### Solve the model\n",
    "#dd-cell\n",
    "assert mdl.solve(), \"!!! Solve of the model fails\"\n",
    "#dd-cell\n",
    "mdl.report()\n",
    "#dd-markdown ### Extract solution value for selected variables\n",
    "#dd-cell\n",
    "df_selected = df_selected.selected.apply(lambda v: v.solution_value)\n",
    "df_selected.head()\n",
    "#dd-markdown ### Build output data frame\n",
    "#dd-cell\n",
    "df_selected = df_selected.reset_index()\n",
    "df_candidate = df_candidate.reset_index();\n",
    "df_selected['expected revenue'] = df_selected.selected * df_candidate['expected value']\n",
    "\n",
    "df_selected.head()\n",
    "#dd-markdown And add it to outputs dictionnary so that it is exported to scenario\n",
    "#dd-cell\n",
    "outputs = {}\n",
    "outputs['selected'] = df_selected\n",
    "        \n",
    "# Generate output files\n",
    "write_all_outputs(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "def reset(tarinfo):\n",
    "    tarinfo.uid = tarinfo.gid = 0\n",
    "    tarinfo.uname = tarinfo.gname = \"root\"\n",
    "    return tarinfo\n",
    "tar = tarfile.open(\"model.tar.gz\", \"w:gz\")\n",
    "tar.add(\"model/main.py\", arcname=\"main.py\", filter=reset)\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='upload'></a>\n",
    "### Upload your model on Watson Machine Learning\n",
    "\n",
    "Store model in Watson Machine Learning with:\n",
    "* the tar archive previously created,\n",
    "* metadata including the model type and runtime\n",
    "\n",
    "Get the `model_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------  ----  --------  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "META_PROP NAME            TYPE  REQUIRED  SCHEMA\n",
      "NAME                      str   Y\n",
      "DESCRIPTION               str   N\n",
      "INPUT_DATA_SCHEMA         dict  N         {'id(required)': 'string', 'fields(required)': [{'name(required)': 'string', 'type(required)': 'string', 'nullable(optional)': 'string'}]}\n",
      "TRAINING_DATA_REFERENCES  list  N         [{'name(optional)': 'string', 'type(required)': 'string', 'connection(required)': {'endpoint_url(required)': 'string', 'access_key_id(required)': 'string', 'secret_access_key(required)': 'string'}, 'location(required)': {'bucket': 'string', 'path': 'string'}, 'schema(optional)': {'id(required)': 'string', 'fields(required)': [{'name(required)': 'string', 'type(required)': 'string', 'nullable(optional)': 'string'}]}}]\n",
      "OUTPUT_DATA_SCHEMA        dict  N         {'id(required)': 'string', 'fields(required)': [{'name(required)': 'string', 'type(required)': 'string', 'nullable(optional)': 'string'}]}\n",
      "LABEL_FIELD               str   N\n",
      "TRANSFORMED_LABEL_FIELD   str   N\n",
      "RUNTIME_UID               str   N\n",
      "TAGS                      list  N         [{'value(required)': 'string', 'description(optional)': 'string'}]\n",
      "SIZE                      dict  N         {'in_memory(optional)': 'string', 'content(optional)': 'string'}\n",
      "SPACE_UID                 str   N\n",
      "PIPELINE_UID              str   N\n",
      "RUNTIME_UID               str   Y\n",
      "TYPE                      str   Y\n",
      "CUSTOM                    dict  N\n",
      "DOMAIN                    str   N\n",
      "HYPER_PARAMETERS          dict  N\n",
      "METRICS                   list  N\n",
      "IMPORT                    dict  N         {'name(optional)': 'string', 'type(required)': 'string', 'connection(required)': {'endpoint_url(required)': 'string', 'access_key_id(required)': 'string', 'secret_access_key(required)': 'string'}, 'location(required)': {'bucket': 'string', 'path': 'string'}}\n",
      "TRAINING_LIB_UID          str   N\n",
      "------------------------  ----  --------  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# All available meta data properties \n",
    "\n",
    "client.repository.ModelMetaNames.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------  --------------------------  ------------------------  --------\n",
      "GUID                        NAME                        CREATED                   PLATFORM\n",
      "xgboost_0.82-py3.6          xgboost_0.82-py3.6          2019-08-02T06:02:55.531Z  python\n",
      "xgboost_0.80-py3.6          xgboost_0.80-py3.6          2019-08-02T06:02:52.157Z  python\n",
      "scikit-learn_0.20-py3.6     scikit-learn_0.20-py3.6     2019-08-02T06:02:45.108Z  python\n",
      "scikit-learn_0.19-py3.6     scikit-learn_0.19-py3.6     2019-08-02T06:02:41.790Z  python\n",
      "tensorflow_1.13-py3.6       tensorflow_1.13-py3.6       2019-08-02T06:02:34.144Z  python\n",
      "tensorflow_1.11-py3.6       tensorflow_1.11-py3.6       2019-08-02T06:02:31.678Z  python\n",
      "tensorflow_1.5-py3.6        tensorflow_1.5-py3.6        2019-08-02T06:02:12.855Z  python\n",
      "ai-function_0.1-py3.6       ai-function_0.1-py3.6       2019-07-05T12:02:38.754Z  python\n",
      "xgboost_0.82-py3            xgboost_0.82-py3            2019-07-05T12:02:33.447Z  python\n",
      "spss-modeler_18.2           spss-modeler_18.2           2019-07-05T12:02:29.092Z  spss\n",
      "scikit-learn_0.20-py3       scikit-learn_0.20-py3       2019-07-05T12:02:24.736Z  python\n",
      "pmml_4.3                    pmml_4.3                    2019-04-15T09:59:34.202Z  pmml\n",
      "pmml_4.2                    pmml_4.2                    2019-04-15T09:59:30.855Z  pmml\n",
      "pmml_4.1                    pmml_4.1                    2019-04-15T09:59:28.401Z  pmml\n",
      "pmml_4.0                    pmml_4.0                    2019-04-15T09:59:25.948Z  pmml\n",
      "pmml_3.2                    pmml_3.2                    2019-04-15T09:59:23.480Z  pmml\n",
      "pmml_3.1                    pmml_3.1                    2019-04-15T09:59:20.942Z  pmml\n",
      "pmml_3.0                    pmml_3.0                    2019-04-15T09:59:18.466Z  pmml\n",
      "do_12.9                     do_12.9                     2019-04-04T10:55:24.375Z  do\n",
      "pmml_4.2.1                  pmml_4.2.1                  2019-04-04T10:55:21.561Z  pmml\n",
      "ai-function_0.1-py3         ai-function_0.1-py3         2019-04-04T10:55:18.663Z  python\n",
      "hybrid_0.2                  hybrid_0.2                  2019-04-04T10:55:15.872Z  hybrid\n",
      "hybrid_0.1                  hybrid_0.1                  2019-04-04T10:55:13.073Z  hybrid\n",
      "xgboost_0.80-py3            xgboost_0.80-py3            2019-04-04T10:55:10.280Z  python\n",
      "xgboost_0.6-py3             xgboost_0.6-py3             2019-04-04T10:55:07.493Z  python\n",
      "spss-modeler_18.1           spss-modeler_18.1           2019-04-04T10:55:04.706Z  spss\n",
      "spss-modeler_17.1           spss-modeler_17.1           2019-04-04T10:55:01.919Z  spss\n",
      "scikit-learn_0.19-py3       scikit-learn_0.19-py3       2019-04-04T10:54:59.060Z  python\n",
      "scikit-learn_0.17-py3       scikit-learn_0.17-py3       2019-04-04T10:54:56.269Z  python\n",
      "spark-mllib_2.3             spark-mllib_2.3             2019-04-04T10:54:53.422Z  spark\n",
      "spark-mllib_2.2             spark-mllib_2.2             2019-04-04T10:54:50.637Z  spark\n",
      "spark-mllib_2.1             spark-mllib_2.1             2019-04-04T10:54:47.851Z  spark\n",
      "tensorflow_1.13-py3         tensorflow_1.13-py3         2019-04-04T10:54:45.039Z  python\n",
      "tensorflow_1.13-py2         tensorflow_1.13-py2         2019-04-04T10:54:42.256Z  python\n",
      "tensorflow_0.11-horovod     tensorflow_0.11-horovod     2019-04-04T10:54:39.420Z  native\n",
      "tensorflow_1.11-py3         tensorflow_1.11-py3         2019-04-04T10:54:36.622Z  python\n",
      "tensorflow_1.10-py3         tensorflow_1.10-py3         2019-04-04T10:54:33.741Z  python\n",
      "tensorflow_1.10-py2         tensorflow_1.10-py2         2019-04-04T10:54:30.915Z  python\n",
      "tensorflow_1.9-py3          tensorflow_1.9-py3          2019-04-04T10:54:27.968Z  python\n",
      "tensorflow_1.9-py2          tensorflow_1.9-py2          2019-04-04T10:54:25.170Z  python\n",
      "tensorflow_1.8-py3          tensorflow_1.8-py3          2019-04-04T10:54:22.330Z  python\n",
      "tensorflow_1.8-py2          tensorflow_1.8-py2          2019-04-04T10:54:19.534Z  python\n",
      "tensorflow_1.7-py3          tensorflow_1.7-py3          2019-04-04T10:54:16.741Z  python\n",
      "tensorflow_1.7-py2          tensorflow_1.7-py2          2019-04-04T10:54:13.963Z  python\n",
      "tensorflow_1.6-py3          tensorflow_1.6-py3          2019-04-04T10:54:11.163Z  python\n",
      "tensorflow_1.6-py2          tensorflow_1.6-py2          2019-04-04T10:54:08.371Z  python\n",
      "tensorflow_1.5-py2-ddl      tensorflow_1.5-py2-ddl      2019-04-04T10:54:05.592Z  python\n",
      "tensorflow_1.5-py3-horovod  tensorflow_1.5-py3-horovod  2019-04-04T10:54:02.749Z  python\n",
      "tensorflow_1.5-py3          tensorflow_1.5-py3          2019-04-04T10:53:59.968Z  python\n",
      "tensorflow_1.5-py2          tensorflow_1.5-py2          2019-04-04T10:53:57.099Z  python\n",
      "--------------------------  --------------------------  ------------------------  --------\n",
      "Note: Only first 50 records were displayed. To display more use 'limit' parameter.\n"
     ]
    }
   ],
   "source": [
    "# All available runtimes\n",
    "\n",
    "client.runtimes.list(pre_defined=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a8eff467-570f-46bd-814a-59ee2f2fc047\n"
     ]
    }
   ],
   "source": [
    "mnist_metadata = {\n",
    "    client.repository.ModelMetaNames.NAME: \"MarketingSmall\",\n",
    "    client.repository.ModelMetaNames.DESCRIPTION: \"MarketingSmall\",\n",
    "    client.repository.ModelMetaNames.TYPE: \"do-docplex_12.9\",\n",
    "    client.repository.ModelMetaNames.RUNTIME_UID: \"do_12.9\"    \n",
    "}\n",
    "\n",
    "model_details = client.repository.store_model(model='/home/dsxuser/work/model.tar.gz', meta_props=mnist_metadata)\n",
    "\n",
    "model_uid = client.repository.get_model_uid(model_details)\n",
    "\n",
    "print( model_uid )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='deploy'></a>\n",
    "### Create a deployment \n",
    "\n",
    "Create a batch deployment for the model, providing information such as:\n",
    "* the maximum number of compute nodes\n",
    "* the T-shirt size of the compute nodes\n",
    "\n",
    "Get the `deployment_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "Synchronous deployment creation for uid: 'a8eff467-570f-46bd-814a-59ee2f2fc047' started\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "\n",
      "ready\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "Successfully finished deployment creation, deployment_uid='70cd7e87-af6f-4a72-b12a-b74b2e03057a'\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "70cd7e87-af6f-4a72-b12a-b74b2e03057a\n"
     ]
    }
   ],
   "source": [
    "meta_props = {\n",
    "    client.deployments.ConfigurationMetaNames.NAME: \"MarketingSmall Deployment\",\n",
    "    client.deployments.ConfigurationMetaNames.DESCRIPTION: \"MarketingSmall Deployment\",\n",
    "    client.deployments.ConfigurationMetaNames.BATCH: {},\n",
    "    client.deployments.ConfigurationMetaNames.COMPUTE: {'name': 'S', 'nodes': 1}\n",
    "}\n",
    "\n",
    "deployment_details = client.deployments.create(model_uid, meta_props=meta_props)\n",
    "\n",
    "deployment_uid = client.deployments.get_uid(deployment_details)\n",
    "\n",
    "print( deployment_uid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------  -------------------------  -----  ------------------------  -------------\n",
      "GUID                                  NAME                       STATE  CREATED                   ARTIFACT_TYPE\n",
      "70cd7e87-af6f-4a72-b12a-b74b2e03057a  MarketingSmall Deployment  ready  2019-08-14T13:47:35.196Z  model\n",
      "0c2372bf-436d-41f3-b4a4-daeadefff192  MarketingSmall Deployment  ready  2019-08-14T13:43:59.005Z  model\n",
      "e12f8103-7eb6-4f1c-b650-e779000e4bbd  deploy2                    ready  2019-01-11T10:50:08.771Z  model\n",
      "ecbae8be-a340-4255-bc66-02e7040019bf  PredictDeployedSvc         ready  2019-01-08T14:03:49.576Z  model\n",
      "------------------------------------  -------------------------  -----  ------------------------  -------------\n"
     ]
    }
   ],
   "source": [
    "# List all existing deployments\n",
    "\n",
    "client.deployments.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='job'></a>\n",
    "### Create and monitor a job with inline data for your deployed model\n",
    "\n",
    "Create a payload containing inline input data.\n",
    "\n",
    "Create a new job with this payload and the deployment.\n",
    "\n",
    "Get the `job_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>max customers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Auto</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Travel</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  max customers\n",
       "0    Home              3\n",
       "1    Auto              3\n",
       "2  Travel              3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "client_5aea6b8defe6477eb3bb359a3ad797c8 = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='vyscBetMpPlUTXIy_oGwoM89y3Ta7C_-kAOS8SzbMFD7',\n",
    "    ibm_auth_endpoint=\"https://iam.eu-de.bluemix.net/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3.eu-geo.objectstorage.service.networklayer.com')\n",
    "\n",
    "body = client_5aea6b8defe6477eb3bb359a3ad797c8.get_object(Bucket='do4wsmarketingcampaignshandson-donotdelete-pr-17nh3lvgn7be59',Key='candidate.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "candidate = pd.read_csv(body)\n",
    "candidate.head()\n",
    "\n",
    "body = client_5aea6b8defe6477eb3bb359a3ad797c8.get_object(Bucket='do4wsmarketingcampaignshandson-donotdelete-pr-17nh3lvgn7be59',Key='customer.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "customer = pd.read_csv(body)\n",
    "customer.head()\n",
    "\n",
    "body = client_5aea6b8defe6477eb3bb359a3ad797c8.get_object(Bucket='do4wsmarketingcampaignshandson-donotdelete-pr-17nh3lvgn7be59',Key='campaign-1.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "campaign = pd.read_csv(body)\n",
    "campaign.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9b5eb83c-2e53-4a05-bb7a-6f85d22f9c2b\n"
     ]
    }
   ],
   "source": [
    "solve_payload = {\n",
    "    client.deployments.DecisionOptimizationMetaNames.INPUT_DATA: [\n",
    "        {\n",
    "            \"id\":\"customer.csv\",\n",
    "            \"values\" : customer\n",
    "        },\n",
    "        {\n",
    "            \"id\":\"campaign.csv\",\n",
    "            \"values\" : campaign\n",
    "        },\n",
    "        {\n",
    "            \"id\":\"candidate.csv\",\n",
    "            \"values\" : candidate\n",
    "        }\n",
    "    ],\n",
    "    client.deployments.DecisionOptimizationMetaNames.OUTPUT_DATA: [\n",
    "    {\n",
    "        \"id\":\".*\\.csv\"\n",
    "    }\n",
    "    ]\n",
    "}\n",
    "\n",
    "job_details = client.deployments.create_job(deployment_uid, solve_payload)\n",
    "job_uid = client.deployments.get_job_uid(job_details)\n",
    "\n",
    "print( job_uid )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display job status until it is completed.\n",
    "\n",
    "The first job of a new deployment might take some time as a compute node must be started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queued...\n",
      "queued...\n",
      "queued...\n",
      "queued...\n",
      "running...\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "while job_details['entity']['decision_optimization']['status']['state'] not in ['completed', 'failed', 'canceled']:\n",
    "    print(job_details['entity']['decision_optimization']['status']['state'] + '...')\n",
    "    sleep(5)\n",
    "    job_details=client.deployments.get_job_details(job_uid)\n",
    "\n",
    "print( job_details['entity']['decision_optimization']['status']['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'details': {'PROGRESS_GAP': '0.0',\n",
       "  'MODEL_DETAIL_NONZEROS': '60',\n",
       "  'MODEL_DETAIL_TYPE': 'MILP',\n",
       "  'MODEL_DETAIL_CONTINUOUS_VARS': '0',\n",
       "  'MODEL_DETAIL_CONSTRAINTS': '13',\n",
       "  'KPI.Expected revenue': '770',\n",
       "  'PROGRESS_CURRENT_OBJECTIVE': '770',\n",
       "  'MODEL_DETAIL_INTEGER_VARS': '0',\n",
       "  'MODEL_DETAIL_KPIS': '[\"Expected revenue\"]',\n",
       "  'MODEL_DETAIL_BOOLEAN_VARS': '30',\n",
       "  'PROGRESS_BEST_OBJECTIVE': '770.0'},\n",
       " 'solve_status': 'optimal_solution'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_details['entity']['decision_optimization']['solve_state']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='display'></a>\n",
    "### Extract and display solution\n",
    "\n",
    "Display the output solution.\n",
    "\n",
    "Display the KPI Total Calories value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Expected revenue</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               NAME  VALUE\n",
       "0  Expected revenue    770"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe for the solution\n",
    "solution = pd.DataFrame(job_details['entity']['decision_optimization']['output_data'][0]['values'], \n",
    "                        columns = job_details['entity']['decision_optimization']['output_data'][0]['fields'])\n",
    "solution.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following method to delete the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.deployments.delete(deployment_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "### Summary and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You successfully completed this notebook! \n",
    "\n",
    "You've learned how to:\n",
    "\n",
    "- work with the Watson Machine Learning client\n",
    "- prepare your model archive and upload your model on Watson Machine Learning\n",
    "- create a deployment\n",
    "- create and monitor a job with inline data for your deployed model\n",
    "- display the solution\n",
    "\n",
    "Check out our online documentation at <a href=\"https://dataplatform.cloud.ibm.com/docs\" target=\"_blank\" rel=\"noopener noreferrer\">https://dataplatform.cloud.ibm.com/docs</a> for more samples, tutorials and documentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright © 2019. This notebook and its source code are released under the terms of the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n",
    "<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n",
    "<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n",
    "<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n",
    "<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
